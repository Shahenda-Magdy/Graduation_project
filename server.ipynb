{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASAU\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "Test Score: 2.300771713256836\n",
      "Test Accuracy: 0.0989999994635582\n",
      "5680\n",
      "Socket is bound to an address & port number.\n"
     ]
    }
   ],
   "source": [
    "# import flwr as fl\n",
    "import threading\n",
    "import math\n",
    "# import mxnet as mx\n",
    "# from mxnet import nd, autograd, gluon\n",
    "# import numpy as np\n",
    "# from copy import deepcopy\n",
    "# import time\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "# from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import pygad.kerasga\n",
    "import time\n",
    "import sys\n",
    "# import numpy as np\n",
    "import random\n",
    "import string\n",
    "import socket\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import sys\n",
    "# import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# from numpy import average\n",
    "# from numpy import array\n",
    "import pickle\n",
    "# from noknow.core import ZK, ZKSignature, ZKParameters, ZKData, ZKProof\n",
    "import pandas as pd\n",
    "# from numpy import genfromtxt\n",
    "import matplotlib.pyplot as plt\n",
    "# from numpy.random import multivariate_normal\n",
    "# Synthetic dataset\n",
    "# from sklearn.datasets import make_classification\n",
    "# Data processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# from collections import Counter\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# Model and performance\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, losses\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import classification_report\n",
    "# from sklearn.metrics import f1_score\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def getData(dist, x, y):\n",
    "#     dx = []\n",
    "#     dy = []\n",
    "#     counts = [0 for i in range(10)]\n",
    "#     for i in range(len(x)):\n",
    "#         if counts[y[i]] < dist[y[i]]:\n",
    "#             dx.append(x[i])\n",
    "#             dy.append(y[i])\n",
    "#             counts[y[i]] += 1\n",
    "\n",
    "#     return np.array(dx), np.array(dy)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "#because of multiclass datasets\n",
    "from keras.utils.np_utils import to_categorical \n",
    "import random\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "assert(x_train.shape[0] == y_train.shape[0]), \"The number of images is not equal ..\"\n",
    "assert(x_test.shape[0] == y_test.shape[0]), \"The number of images is not equal ..\"\n",
    "assert(x_train.shape[1:] == (28, 28)), \"The dimension of the images are not 28x28\"\n",
    "assert(x_test.shape[1:] == (28, 28))\n",
    "num_of_samples = []\n",
    "\n",
    "cols = 5\n",
    "num_of_classes = 10\n",
    "\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10) \n",
    "x_train = x_train/255 \n",
    "x_test = x_test/255\n",
    "num_pixels = 784\n",
    "x_train = x_train.reshape(x_train.shape[0],\n",
    "                         num_pixels)\n",
    "x_test = x_test.reshape(x_test.shape[0],\n",
    "                         num_pixels)\n",
    "# print(x_train.shape)\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, input_dim = num_pixels,\n",
    "                    activation = 'relu'))\n",
    "    model.add(Dense(30, activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(num_of_classes, activation='softmax'))\n",
    "    model.compile(Adam(lr=0.01),\n",
    "                    loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "    return model           \n",
    "     \n",
    "\n",
    "globalmodel = create_model()\n",
    "# print(model.summary())\n",
    "# history = model.fit(x_train, y_train, validation_split=0.1,\n",
    "#          epochs=10, batch_size=200, verbose=1, shuffle=1)\n",
    "\n",
    "score = globalmodel.evaluate(x_test, y_test, verbose=0)\n",
    "print(type(score))\n",
    "print('Test Score:', score[0])\n",
    "print('Test Accuracy:', score[1])\n",
    "\n",
    "class SocketThread(threading.Thread):\n",
    "\n",
    "    def __init__(self, buffer_size, port,std,lg,m,i):\n",
    "        threading.Thread.__init__(self)\n",
    "        self.buffer_size = buffer_size\n",
    "        self.port=port\n",
    "        print(self.port)\n",
    "        self.soc = socket.socket(family=socket.AF_INET, type=socket.SOCK_STREAM)\n",
    "        self.soc.bind((\"192.168.56.1\" , self.port))\n",
    "        print(\"Socket is bound to an address & port number.\")\n",
    "        self.soc.listen(1)\n",
    "        self.connection, client_info = self.soc.accept()\n",
    "        self.std=std\n",
    "        self.lg=lg\n",
    "        self.m=m\n",
    "        self.i=i\n",
    "        \n",
    "\n",
    "    def run(self):\n",
    "        print(\"Running a Thread for the Connection with client\")\n",
    "        \n",
    "\n",
    "        # This while loop allows the server to wait for the client to send data more than once within the same connection.\n",
    "        while True:\n",
    "            received_data = self.recv()\n",
    "\n",
    "            # print(received_data)\n",
    "            self.reply(received_data)\n",
    "\n",
    "    def recv(self):\n",
    "        print(\"nnnn\")\n",
    "        received_data = b\"\"\n",
    "        while True:\n",
    "            try:\n",
    "                data = self.connection.recv(self.buffer_size)\n",
    "                received_data = data\n",
    "                \n",
    "                if len(received_data) > 0:\n",
    "                    print('hnn')\n",
    "                    try:\n",
    "                        # Decoding the data (bytes).\n",
    "                        received_data = pickle.loads(received_data)\n",
    "                        # Returning the decoded data.\n",
    "                        return received_data\n",
    "\n",
    "                    except BaseException as e:\n",
    "                        print(\"Error Decoding the Client's Data:\")\n",
    "                        return\n",
    "\n",
    "                # else:\n",
    "                #     # In case data are received from the client, update the recv_start_time to the current time to reset the timeout counter.\n",
    "                #     self.recv_start_time = time.time()\n",
    "\n",
    "            except BaseException as e:\n",
    "                print(\"Error Receiving Data from the Client: \")\n",
    "                return\n",
    "\n",
    "        #return received_data\n",
    "\n",
    "    def reply(self, received_data):\n",
    "        global keras_ga,data_inputs, data_outputs,globalmodel\n",
    "        # if ((\"data\" in received_data.keys()) and (\"subject\" in received_data.keys())):\n",
    "        #     subject = received_data[\"subject\"]\n",
    "        #  msg_model = received_data\n",
    "            # print(\"Client's Message Subject is {subject}.\".format(subject=subject))\n",
    "    \n",
    "        print(\"Replying to the Client.\")\n",
    "        if received_data is None:\n",
    "            print(\"nothong received from client\")\n",
    "            # data_dict = {\"population_weights\": keras_ga.population_weights,\n",
    "            #                 \"model_json\": globalmodel.to_json(),\n",
    "            #                 \"num_solutions\": keras_ga.num_solutions}\n",
    "            # data = {\"subject\": \"model\", \"data\": data_dict}\n",
    "        else:\n",
    "            score = globalmodel.evaluate(x_test, y_test, verbose=0)\n",
    "            print(type(score))\n",
    "            print('Test Score:', score[0])\n",
    "            print('Test Accuracy:', score[1])\n",
    "            if score[1] == 1.0:\n",
    "                print(\"model is updated correctly\")\n",
    "                self.soc.close()\n",
    "                return\n",
    "            else:\n",
    "                try:\n",
    "                    response = pickle.dumps(globalmodel)\n",
    "                    self.model_averaging(globalmodel, received_data)\n",
    "                except BaseException as e:\n",
    "                    print(\"Error Encoding the Message: {msg}.\\n\".format(msg=e))\n",
    "        score = globalmodel.evaluate(x_test, y_test, verbose=0)\n",
    "        print('Test Score:', score[0])\n",
    "        print('Test Accuracy:', score[1])\n",
    "        if score[1] != 1.0:\n",
    "\n",
    "            response = pickle.dumps(globalmodel)\n",
    "            self.model_averaging(globalmodel, received_data)\n",
    "            print(\"done\")\n",
    "        else:\n",
    "            self.soc.close()\n",
    "            print(\"done\")\n",
    "            return\n",
    "        try:\n",
    "            self.connection.sendall(response)\n",
    "        except BaseException as e:\n",
    "            print(\"Error Sending Data to the Client: {msg}.\\n\".format(msg=e))\n",
    "\n",
    "\n",
    "    def model_averaging(self, model, received):\n",
    "        model_weights_vector = pygad.kerasga.model_weights_as_vector(model=model)\n",
    "        model_weights_matrix = pygad.kerasga.model_weights_as_matrix(model=model,\n",
    "                                                                     weights_vector=model_weights_vector)\n",
    "        best_model_weights_vector = pygad.kerasga.model_weights_as_vector(model=received)\n",
    "        best_model_weights_matrix = pygad.kerasga.model_weights_as_matrix(model=received,weights_vector=best_model_weights_vector)\n",
    "       \n",
    "        \n",
    "        new_weights = np.array(len(model_weights_matrix)*2)\n",
    "        best=np.array(len(best_model_weights_matrix))\n",
    "        for i in range(0,len((model_weights_matrix))):\n",
    "            new_weights=np.append(new_weights,model_weights_matrix[i])\n",
    "        for i in range(0,len((best_model_weights_matrix))):\n",
    "            best=np.append(best,best_model_weights_matrix[i])\n",
    "        wts=np.array(len(model_weights_matrix))\n",
    "        for idx, arr in enumerate(model_weights_matrix):\n",
    "            x=new_weights[idx]\n",
    "            l=x+best[idx]\n",
    "            x=l/2\n",
    "            wts=np.append(wts,x)\n",
    "        # f=new_weights.reshape(30,10)\n",
    "        # b=best.reshape(30,10)\n",
    "        try:\n",
    "            new_wei = model_weights_matrix\n",
    "            for idx, arr in enumerate(new_wei):\n",
    "                new_wei[idx] = new_wei[idx] + best_model_weights_matrix[idx]\n",
    "                new_wei[idx] = new_wei[idx] / 2\n",
    "        except:\n",
    "            print(\"malicious client\")\n",
    "            for self.i in range(8):\n",
    "                print(\"client:\",self.i)\n",
    "                p=self.port\n",
    "                # self.port=self.port+1\n",
    "                b=self.port+1\n",
    "                listenThread = SocketThread(buffer_size=1024*1024*1024,\n",
    "                                                  port=b,std=self.std,lg=self.lg,m=self.m,i=self.i+1)\n",
    "                break\n",
    "                # if p==5680:\n",
    "                #     print(\"client 1\")\n",
    "            self.soc.close()\n",
    "        \n",
    "        \n",
    "            # new_weights[idx]= new_weights[idx]+best[idx]\n",
    "        # print(\"lenght\",len(new_weights))\n",
    "        # print(wts)\n",
    "        N=10\n",
    "        h=np.array(len(model.get_weights()))\n",
    "        for i in range(0, len(model.get_weights()) // N):\n",
    "        \n",
    "            # getting incremented chunks\n",
    "            h.append(model.get_weights()[0: (i + 1) * N])\n",
    "        x=np.array(len(model.get_weights()))\n",
    "        zip_object = zip(wts, model.get_weights())\n",
    "\n",
    "        for i, k in zip_object:\n",
    "            x=np.append(x,i - k)\n",
    "        # print(x)\n",
    "        x=np.matrix(x)\n",
    "        def determinant_recursive(A, total=0):\n",
    "    # Section 1: store indices in list for row referencing\n",
    "            indices = list(range(len(A)))\n",
    "     \n",
    "    # Section 2: when at 2x2 submatrices recursive calls end\n",
    "            if len(A) == 2 and len(A[0]) == 2:\n",
    "                val = A[0][0] * A[1][1] - A[1][0] * A[0][1]\n",
    "                return val\n",
    "        \n",
    "            # Section 3: define submatrix for focus column and \n",
    "            #      call this function\n",
    "            for fc in indices: # A) for each focus column, ...\n",
    "                # find the submatrix ...\n",
    "                As = A # B) make a copy, and ...\n",
    "                As = As[1:] # ... C) remove the first row\n",
    "                height = len(As) # D) \n",
    "        \n",
    "                for i in range(height): \n",
    "                    # E) for each remaining row of submatrix ...\n",
    "                    #     remove the focus column elements\n",
    "                    As[i] = As[i][0:fc] + As[i][fc+1:] \n",
    "        \n",
    "                sign = (-1) ** (fc % 2) # F) \n",
    "                # G) pass submatrix recursively\n",
    "                sub_det = determinant_recursive(As)\n",
    "                # H) total all returns from recursion\n",
    "                total += sign * A[0][fc] * sub_det \n",
    "        \n",
    "            return total\n",
    "        z=determinant_recursive(x, total=0)\n",
    "        print(len(x))\n",
    "        h=np.add(h,z)\n",
    "        # c=np.array(len(x))\n",
    "        # for i in range(0,len(x)):\n",
    "        #     c=np.append(x[i]*h[i])\n",
    "        g=model=+h\n",
    "  \n",
    "        print(len(wts))\n",
    "        try:\n",
    "            globalmodel.set_weights(weights=new_wei)\n",
    "        except:\n",
    "            print(\"malicious client\")\n",
    "            for self.i in range(8):\n",
    "                print(\"client:\",self.i)\n",
    "                p=self.port\n",
    "                # self.port=self.port+1s\n",
    "                b=self.port+1\n",
    "                listenThread = SocketThread(buffer_size=1024*1024*1024,\n",
    "                                                    port=b,std=self.std,lg=self.lg,m=self.m,i=self.i+1)\n",
    "                break\n",
    "                # if p==5680:\n",
    "                #     print(\"client 1\")\n",
    "            self.soc.close()\n",
    "    \n",
    "        dist=np.linalg.norm(new_weights-best)\n",
    "        print(\"distance:\" ,dist)\n",
    "        td=self.std\n",
    "        d1=np.append(td,dist)\n",
    "        p=self.port\n",
    "        for self.i in range(8):\n",
    "            print(\"client:\",self.i)\n",
    "            # self.port=self.port+1\n",
    "            b=self.port+1\n",
    "            listenThread = SocketThread(buffer_size=1024*1024*1024,\n",
    "                                                port=b,std=d1,lg=self.lg,m=self.m,i=self.i+1)\n",
    "            break\n",
    "\n",
    "        s=np.std(d1, axis = 0)\n",
    "        for i in range(len(s)):\n",
    "            # print(s[i])\n",
    "            if s[i]<self.m:\n",
    "                self.m=s[i]\n",
    "            if s[i]>self.lg:\n",
    "                self.lg=s[i]\n",
    "        s=np.std(std, axis = 0)\n",
    "        # if p==5680:\n",
    "        #     print(\"client 1\")\n",
    "        \n",
    "        # lock = threading.Lock()\n",
    "        # lock.acquire()\n",
    "        # stop=threading\n",
    "        if dist>self.lg:\n",
    "            print(\"malicious client\")\n",
    "            self.soc.close()\n",
    "        elif dist<self.getNamem:\n",
    "            print(\"malicious client\")\n",
    "            self.soc.close()\n",
    "        else:\n",
    "            print(\"client is un malicious\")\n",
    "        \n",
    "port= 5680\n",
    "\n",
    "m=100\n",
    "lg=0\n",
    "std=[]\n",
    "# for i in range(1):\n",
    "i=0\n",
    "listenThread = SocketThread(buffer_size=1024*1024*1024,\n",
    "                                            port=port,std=std,lg=lg,m=m,i=i)\n",
    "listenThread.start()\n",
    "print(\"Listening for incoming connection ...\")\n",
    "    # port+=1\n",
    "    \n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3ebaef70996a164ed53f0d2818090252f1afc348cdb48186a1059b38e106d308"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
